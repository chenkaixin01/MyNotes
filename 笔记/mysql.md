# 数据查询流程

一次数据查询会经过数据库的客户端管理器，查询管理器，数据管理器，客户端管理器

## 查询管理器

![](https://pdai.tech/images/db/sb-sql-learn-3.png)

这个多步骤操作过程如下：

- 查询首先被**解析**并判断是否合法

- 然后被**重写**，去除了无用的操作并且加入**预优化**部分

- 接着被**优化**以便提升性能，并被**转换为可执行代码**和**数据访问计划**。

- 然后计划被**编译**

- 最后，被**执行**

### 查询解析器

1. 检查sql语法

2. 检查表，表字段等元数据是否存在

3. 检查sql中的运算是否可行

4. 检查当前请求是否有足够权限

5. 检查结束后，sql将被转换为数据库内部表示，并发给查询重写器

### 查询重写器

#### 查询重写器目标

1. 预优化查询

2. 避免不必要的计算

3. 帮助优化器找到合适的最佳解决方案

#### 查询器的部分优化规则

1. 合并视图：如果在sql中使用了视图，重写器会将其转换为查询语句

2. 消除不必要的计算：例如对一个uinion索引字段添加distinct

3. 子查询扁平化：对于数据库而言子查询难以优化，重写器会尝试移除子查询

4. 排查冗余的连接：比如重复的inner join

5. 常量计算：比如field_name=10+2;优化结果为field_name=12

### 查询优化器

> 所有的现代数据库都在用**基于成本的优化**（即CBO）来优化查询。道理是针对每个运算设置一个成本，通过应用成本最低廉的一系列运算，来找到最佳的降低查询成本的方法。

#### 统计信息

**统计信息会帮助优化器估计查询所需的磁盘 I/O、CPU、和内存使用**

MySQL统计信息是指数据库通过采样、统计出来的表、索引的相关信息，例如，表的记录数、聚集索引page个数、字段的Cardinality....。在mysql8还提供了直方图，如最频繁出现的值等；mysql默认每天重新统计，或者表数据变动10%；当表只读时，统计信息不在更改

#### 优化器考虑的成本

1. 索引：索引是有序的

2. 存取路径：获取数据的方式：全扫描，范围扫描（需要有索引），唯一扫描，rowId获取

3. 连接运算符选择：合并联接（Merge join），哈希联接（Hash Join）和嵌套循环联接（Nested Loop Join）；

##### 连接方式

- **嵌套循环联接：** mysql8以前的连接方式，原理是将内关系表（左表）载入内存中，通过双层for循环从磁盘中读取外表数据对比

- **哈希连接：** mysql8出现后，将内表（左表）载入内存构建哈希表，循环读取外表与哈希表匹配。如果内存不足，会将哈希表保存到磁盘，然后通过使用哈希表与外表进行双层for

- **合并连接：** 这个算法，同样在MySql8之前是没有的。上面说到了Hash join是在等值（=）才会去使用的，那非等值(>,<,>=,<=)，这种条件在Mysql8中是是否还是之前的循环算法，答案是NO，然而如果两表已经有序，用的是Merge Join。Merge Join在做非等值(>,<,>=,<=)对比的时候，一旦有行不符合条件就会不往下面再去执行的，因为对比之前就是有序的。

#### 成本计算算法

使用动态规划（中等规模）或者贪心算法（大规模）算出最优解，由子问题最优解推到全局最优解

#### 查询计划缓存

由于创建查询计划是耗时的，大多数据库把计划保存在查询计划缓存，来避免重复计算。这个话题比较大，因为数据库需要知道什么时候更新过时的计划。办法是设置一个上限，如果一个表的统计变化超过了上限，关于该表的查询计划就从缓存中清除。

### 查询执行器

    如果内存cpu等资源足够，执行器会开始执行优化过的计划，与数据管理器交互

## 数据管理器

### 缓存处理器

查询执行器不会直接从文件系统拿数据，而是向缓存管理器要。缓存管理器有一个内存缓存区，叫做缓冲池，从内存读取数据显著地提升数据库性能。内存比磁盘要快100到10万倍。然而，这导致了另一个问题（数据库总是这样…)，缓存管理器需要在查询执行器使用数据之前得到数据，否则查询管理器不得不等待数据从缓慢的磁盘中读出来。数据库对这个问题的解法是预读

#### 预读

查询执行器知道它将需要什么数据，因为它了解整个查询流，而且通过统计也了解磁盘上的数据。过程是这样的：

- 当查询执行器处理它的第一批数据时，会告诉缓存管理器预先装载第二批数据
- 当开始处理第二批数据时，告诉缓存管理器预先装载第三批数据，并且告诉缓存管理器第一批可以从缓存里清掉了。
- 。。。。

#### 缓存置换策略

一般使用LRU，LRU代表最近最少使用（Least Recently Used）算法，背后的原理是：在缓存里保留的数据是最近使用的，所以更有可能再次使用。

# 事务，锁，MVCC

## 事务管理器

一个ACID事务是一个工作单元，它要保证4个属性：

- 原子性（Atomicity）: 事务『要么全部完成，要么全部取消』，即使它持续运行10个小时。如果事务崩溃，状态回到事务之前（事务回滚）。
- 一致性（Consistency）: 只有合法的数据（依照关系约束和函数约束）能写入数据库，一致性与原子性和隔离性有关。
- 隔离性（Isolation）: 如果2个事务 A 和 B 同时运行，事务 A 和 B 最终的结果是相同的，不管 A 是结束于 B 之前/之后/运行期间。
- 持久性（Durability）: 一旦事务提交（也就是成功执行）,不管发生什么（崩溃或者出错），数据要保存在数据库中。

## 并发一致问题

- **脏读：** T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。

- **不可重复读：** T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。

- **幻读：** T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。

## 隔离级别

**未提交读(READ UNCOMMITTED**

事务中的修改，即使没有提交，对其它事务也是可见的。

**提交读(READ COMMITTED**

一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。假设t1事务是长事务，t2事务在t1后发起，在t1前提交，那t2提交的数据对t1可见

**可重复读(REPEATABLE READ**

保证在同一个事务中多次读取同样数据的结果是一样的。与提交读相比，t2提交的数据对t1不可见，通过MVCC和间隙锁，可以解决大部分幻读问题

**可串行化(SERIALIZABLE**

强制事务串行执行。

---

| 隔离级别 | 脏读  | 不可重复读 | 幻影读 |
| ---- | --- | ----- | --- |
| 未提交读 | √   | √     | √   |
| 提交读  | ×   | √     | √   |
| 可重复读 | ×   | ×     | √   |
| 可串行化 | ×   | ×     | ×   |

### MVCC（多版本并发控制）

MVCC是基于Undo Log、隐藏字段、Read View（读视图）实现的。

#### 隐藏字段

当我们创建一张表时，InnoDB引擎会增加2个隐藏字段。

**DB_TRX_ID：** 最近一次提交事务的ID

**DB_ROLL_PTR：** 上个版本记录的ID

#### Read View（读视图）

通过隐藏字段，我们在表与undo日志构成了版本链。当一个事务执行时会生成一个读视图，包含当前正在活动中的事务，当前事务之后的产生的不会再包含

一个读视图包含一下字段

**m_ids** ：当前系统中活跃的事务ID集合，即未提交的事务。在m_ids中的事务不可读

**min_trx_id** ：m_ids中最小的ID，trx_id<min_trx_id代表事务已提交，可读

**max_trx_id** ：下一个要分配的事务ID，trx_id>max_trx_id代表事务在当前事务之后提交，不可读

**creator_trx_id**: 当前事务ID

#### 快照读与当前读

快照读：使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。

当前读：读取的是最新的数据，需要加锁。

# 锁

## 锁粒度

按粒度分，mysql的锁分为表级锁与行级锁

## 锁类型

读写锁：

- 读锁：读锁是共享锁，允许其他读锁获取，但不允许写锁

- 写锁：写锁是独占锁，不允许其他任何锁

意向锁：

使用意向锁(Intention Locks)可以更容易地支持多粒度封锁。

在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。

意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定:

- 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁；
- 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。

通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。

各种表级锁的兼容关系如下:

| -   | X   | IX  | S   | IS  |
| --- | --- | --- | --- | --- |
| X   | ×   | ×   | ×   | ×   |
| IX  | ×   | √   | ×   | √   |
| S   | ×   | ×   | √   | √   |
| IS  | ×   | √   | √   | √   |

**Next-Key Locks**

Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。

MVCC 不能解决幻读的问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读(REPEATABLE READ)隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。

Next-Key Locks是record locks与gap lock的结合

# 日志

![](https://pdai.tech/images/db/mysql/db-mysql-sql-14.png)

## undo log

记录数据变更前的sql，支持MVCC的实现与事务执行失败回滚

## redo log

主要作用是保证事务的持久性。

1. mysql服务崩溃后恢复

2. redo log在磁盘中是顺序写，提高了mysql的写入性能

### 为什么需要写Redo Log Buffer 和 Redo Log Flle?

为什么需要写Redo Log Buffer 和 Redo Log Flle?而不是直接持久化到磁盘？

直接写磁盘会有产生严重的性能问题：
(1)InnoDB在磁盘中存储的基本单元是页，可能本次修改只变更一页中几个字节，但是需要刷新整页的数据，就很浪费资源。
(2)一个事务可能修改了多页中的数据，页之间又是不连续的，就会产生随机IO，性能更差。

这种方案叫做WAL(Write-Ahead Logging),预写日志，就是先写日志，再写磁盘.

### Mysql Redo Log 刷盘时机

- 0，延迟写，表示每次事务提交时都只是把redo log留在redo log buffer中，开启一个后台线程，每1s刷新一次到磁盘中；

- 1，实时写，默认，每次事务提交都将redo log buffer写入磁盘

- 2，实时写延迟刷，

## bin log

| 性质   | redo Log                                             | bin Log                                                     |
| ---- | ---------------------------------------------------- | ----------------------------------------------------------- |
| 文件大小 | redo log 的大小是固定的（配置中也可以设置，一般默认的就足够了）                 | bin log 可通过配置参数max_bin log_size设置每个bin log文件的大小（但是一般不建议修改）。 |
| 实现方式 | redo log是InnoDB引擎层实现的（也就是说是 Innodb 存储引擎独有的）          | bin log是 MySQL 层实现的，所有引擎都可以使用 bin log日志                     |
| 记录方式 | redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。               | bin log 通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上                |
| 使用场景 | redo log适用于崩溃恢复(crash-safe)（这一点其实非常类似与 Redis 的持久化特征） | bin log 适用于主从复制和数据恢复                                        |

bin log 默认先写入缓存，当缓存空间满时刷入磁盘事务执行过程中，先把日志写到binlog cache,事务提交的时候，再把binlogcache写到binlog文件中。

因为一个事务的binlog不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一块内存作为binlog cache。

至于什么时候刷新到磁盘，可以sync_binlog配置参数指定。

0(延迟写)每次提交事务都不会刷盘，由系统自己决定什么时候刷盘，可能会丢失数据。
1(实时写)每次提交事务，都会刷盘，性能较差。
N(延迟写)提交N个事务后，才会刷盘。

# 存储引擎

## InnoDB

是 MySQL 默认的事务型存储引擎，**只有在需要它不支持的特性时，才考虑使用其它存储引擎**。

实现了四个标准的隔离级别，默认级别是可重复读(REPEATABLE READ)。在可重复读隔离级别下，通过多版本并发控制(MVCC)+ 间隙锁(Next-Key Locking)防止幻影读。

主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。

内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。

支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。

## MyISAM

设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。

提供了大量的特性，包括压缩表、空间数据索引等。

**不支持事务**。

不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入(CONCURRENT INSERT)。

可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。

如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。

## 比较

- 事务: InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。

- 并发: MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。

- 外键: InnoDB 支持外键。

- 备份: InnoDB 支持在线热备份。

- 崩溃恢复: MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。

- 其它特性: MyISAM 支持压缩表和空间数据索引。

# 索引

## 聚簇索引

每个`InnoDB`表都有一个特殊的索引，称为聚集索引，用于存储行数据。通常，聚簇索引与主键同义。通过聚簇索引访问行很快，因为索引搜索直接指向包含行数据的页面。如果表很大，与使用与索引记录不同的页来存储行数据的存储组织相比，聚集索引架构通常可以节省磁盘 I/O 操作。    

## 非聚簇索引

聚簇索引以外的索引称为二级索引。在`InnoDB`中，二级索引中的每条记录都包含该行的主键列，以及为二级索引指定的列。

## b+ tree

b+ tree是innoDB的一种索引方式，在聚簇索引中，叶子节点是数据行；在非聚簇索引中，叶子节点是主键ID

# 其他

## mysql的优化方式

### 1、sql层面

  根据实际业务结合explain的提示进行优化，可以有一下修改

- 仅返回必要的列

- 使用limit限制返回的数据量

- 如果对表数据的现在未来的数据量有很明确的判断，可以使用STRAIGHT_JOIN，指定驱动表。否则查询优化器根据实际情况调整驱动表

- 尽量不使用子查询，查询优化器优化子查询比较困难

- 不要让数据库进行类型转换，虽然能召回数据，但可能会不走索引

### 2、业务层面

- 调整字段类型，尽量使用数值类型等字段，对于varchar等字段应尽量短

- **切分大查询：** 一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。

- **切分长连接查询：** 将一个大连接查询分解成对每一个表进行一次单表查询，然后将结果在应用程序中进行关联。好处有：1、提高缓存使用效率；2、减少锁竞争

- 合理添加索引，权衡索引带来的读性能提升与写性能下降；考虑覆盖索引

### 3、表与索引层面

- 

- 表数据过多时，考虑分表；mysql建议两千万以下数据

### 4、MySQL配置调整层面

- 调整缓冲区大小

- 调整连接池大小，MySQL的最大连接数决定了系统同时能处理的最大请求数量

- 配置主从复制，读写分离

### 5、调整硬件配置

增加服务器cpu，内存，应用SSD磁盘等；增加网络带宽等

## 为什么Mysql建议数据量不超过2000万

因为查询性能，mysql建议B+tree层数应限制在3层以下；Innodb默认页大小是16k（16384字节），索引条目假设为14字节；16384/14约为1170；三层为1170的立方，约为两千万

## MySQL 什么时候刷新脏页

1. redo log 写满了：这时候系统会停止所有的更新操作，然后让日志可以继续写。把这部分数据日志都flush到磁盘上面
2. mysql内存满了，发生内存置换。当要置换出去的是脏页时，就会刷脏页；LRU
3. mysql系统空闲时
4. mysql停止服务的时候

## MySQL 主从同步方式

mysql 主从同步三种模式：异步复制、半同步复制、全同步复制

### 异步复制：

异步复制是mysql 默认的同步方式。

在master为slave开通账号密码、ip授权之后，slave 可以从master进行数据同步，主要依赖的是master的binlog日志。

slave会启动两个线程，IO Thread 和 SQL Thread。IO Thread 负责从master拉取binlog 日志，并写入relay中继日志。SQL Thread 负责将relay中继日志中的变更进行重放，更新数据来达到跟master保持数据一致的目的。这个过程中，slave通过IO线程拉取binlog，master无需关注是否有slave需要同步，只做自己的事情，整个复制过程都是异步完成的，这个就是异步复制。

### 半同步复制

master更新操作写入binlog之后会主动通知slave，slave接收到之后写入relay log 即可应答，master只要收到至少一个ack应答，则会提交事务。

### 全同步复制

全同步复制跟半同步复制的区别是，全同步复制必须收到所有从库的ack，才会提交事务。

## MySQL分库分表后再次扩容怎么处理

1. 确保数据库支持读写分离，

2. 用户写入时，往新库写入

3. 读取时新库与老库同时读取

4. 用户更新时，删除老库数据，新增新库数据

## MYSQL索引字段是否允许null

mysql索引字段允许为null存储，但不会对null值创建索引，因为索引本身是对值进行排序，而null无法判断
