# 需求方案

结合大模型能力与ES向量检索能力构造一个下一代企业知识库

1. 内容在线采编与非结构化内容解析（word，excel，pdf，音频，视频，图片等）

2. 内容存入es中创建全文检索索引，进行普通全文检索

3. 内容转向量，执行knn检索

4. 将数据导入大模型，通过向量检索结果结合大模型输出生成文本

# 技术方案

## 数据采集

分为前端在线编辑与数据导入两种方式，在线编辑方式将文档划分为更小的block结构。数据导入内容则需要通过拆分工具拆分为block形式。

## 数据存储

内容数据将存储在多个数据库中，文档内容解析后，会存入MySQL与OSS进行持久化，完成持久化后，会发布到消息队列，Html转换消费者与ES转换消费者分别会执行消费

> **MySQL：** 知识的名称，属性，标签等数据会存储在mysql，与其他业务完成关联查询等
> 
> **OSS：** 文档的主要内容会存储OSS中
> 
> **Nginx：** Html转换消费者将文档主体内容（存在OSS部分）转换为Html，存储到Nginx中，前端查看Nginx详情时，优先通过前端路由进行获取
> 
> **Elasticsearch：** ES消费者获取主体内容（存在OSS部分）后，执行分词与向量计算，然后推送给ES。提供给全文检索，向量检索，RAG功能使用

### 文本拆分

> **word文档：** 使用poi进行解析，以每个paragraph作为单位转换为block
> 
> **PDF文档：**     将pdf内容转换为html，通过解析div之间的关系与内容，转换为block

 对于在线编辑的内容，依赖富文本编辑器quill进行block拆分

对于导入数据，先根据不同的数据类型进行切分；例如word就使用poi提取文字，pdf则将内容转换为html后在根据div之间的关系抽取转换；如果规则解析后文本内容还是超长，则使用语义模型进行再次拆分；对于图片，视频，表格等内容，采用模型将其总结为摘要文本

### 数据转向量

#### embdding

嵌入式模型（Embedding）是一种广泛应用于自然语言处理（NLP）和计算机视觉（CV）等领域的机器学习模型，它可以将高维度的数据转化为低维度的嵌入空间（embedding space），并保留原始数据的特征和语义信息，从而提高模型的效率和准确性。通常使用神经网络进行训练

选用*bge*-large-zh-v1.5模型，采用预训练方式封装成onnx

由于各种嵌入模型发展，为了给未来扩展准备，我们将转向量服务抽成组件，通过spi方式引入不同组件；

> 1、分析向量转换的业务场景，主要有以下几种：文本转向量（长短），图片转向量，音频转向量，视频转向量
> 
> 2、根据上述分析定义api模块；根据不同模型进行不同实现；再结合配置文件激活不同组件

## 向量检索

由于向量数据库百花齐放；我们对向量的操作也采用组件化抽象方式进行开发，对向量数据库的增删改查动作进行了封装

## 向量数据库选择

|                | Milvus                    | Qdrant                                                                    | ES              | ClickHouse               | ByteHouse                                                |
| -------------- | ------------------------- | ------------------------------------------------------------------------- | --------------- | ------------------------ | -------------------------------------------------------- |
| 易扩展性           | 存储计算分离                    | 存储计算耦合                                                                    | 存储计算耦合          | 存储计算耦合                   | 存储计算分离                                                   |
| 易用性            | 自定义API，不支持SQL             | 自定义 API，不支持 SQL                                                           | 自定义 API，不支持 SQL | 支持较全的SQL语法               | 支持较全的SQL语法                                               |
| 混合负载能力         | 支持基于简单类型标量的过滤，不支持聚合       | 支持基于简单标量类型过滤支持基于某个特定标量的 group by 操作（group by key 必须为 string 或 integer 类型） |                 | 支持OLAP和vector search混合场景 | 1.支持OLAP和vector search混合场景2.支持optimizer，可以实现混合负载的CBO自动优化 |
| 混合负载能力         | 支持基于简单类型标量的过滤，不支持聚合       | 支持基于简单标量类型过滤支持基于某个特定标量的 group by 操作（group by key 必须为 string 或 integer 类型） |                 | 支持OLAP和vector search混合场景 | 1.支持OLAP和vector search混合场景2.支持optimizer，可以实现混合负载的CBO自动优化 |
| 索引类型           | HNSW IVF类索引 DiskANN SCANN | HNSW                                                                      |                 | Annoy                    | HNSW/IVFPQ/DiskANN等                                      |
| 支持的数据类型        | 较少                        | 较少                                                                        |                 | 支持常见数据类型                 | 支持常见数据类型                                                 |
| 单表是否支持多个vector | 是                         | 是                                                                         |                 | 是                        | 是                                                        |
| 检索性能           | 高                         | 中                                                                         | 低               | 中                        | 高                                                        |

### Milvus

Milvus的计算节点采用存储计算分离、水平扩展的共享存储架构。Milvus按照数据平面和控制平面分离的原则，分为4层:接入层、协调服务层、工作节点层和存储层。在扩展或灾难恢复方面，这些层是相互独立的。

[如何使用 Milvus 向量数据库实现实时查询](https://maimai.cn/article/detail?fid=1723124757&efid=paPcXivEhzOwWt2Jwc0tQg)

[前所未有的 Milvus 源码架构解析](https://xie.infoq.cn/article/3e779038d570e65b9a19bb3f5)

![](https://milvus.io/docs/v2.4.x/assets/milvus_architecture.png)

### ES

使用ES的knn进行向量检索，默认es使用近似knn进行查询，可以选择精确暴力knn进行处理，但很耗资源。knn默认选择 [HNSW](https://arxiv.org/abs/1603.09320) 进行检索，kNN 算法是一种监督式学习算法

es中向量结构索引为默认为HNSW，可以选择通过配置将其改为flat进行暴力计算

knn有三种相似度计算方式，内积，欧式距离，余弦

优化方式：

> 降低维度
> 
> "_source"字段不存储维度字段，因为 `_source` 可以相当大 装载成本很高。这可能会显著降低kNN搜索的速度。
> 
> es启动预热，`index.store.preload` 设置
> 
> HNSW需要检索每个段的值，段越多越耗费，减少段的数量，只读索引可以强制合并到1个
> 
> 调整es索引缓冲区为堆内存的10分之一，可以减少段的产生

## 重排序

### 规则重排

### LTR

## rag

通过计算答案置信度的方式来评估答案是否可靠，计算的维度包含以下 3 方面：

- 计算问题与答案的相似度，通常情况大语言模型生成的答案与问题的相似度会比较高，偶尔出现相似度比较低的情况，这种情况答案大概率与问题无关，另外偶尔出现相似度非常高的情况，这时答案文本基本是问题文本的重复，这种情况的答案也不能用。
- 计算答案文本与大模型推理使用的相关文本的相似度。如果答案文本与大模型推理使用的相关文本相似度较低，答案文本大概率是模型编造出来的。
- 计算答案文本在数据库召回的相关文本列表，与问题文本在数据库召回的相关文本列表的重合率。如果 2 个列表的重合率低，答案的置信度也会较低。

## 检索反馈
