# Elasticsearch

## 问题

海航现场问答引擎访问es查询超时。到集群（182，183，184）服务器查看，发现183节点的各种指标远高于另外两个节点

## 排查与处理

### GET /_tasks与GET /_tasks/{taskId}

未发现长时间占用资源的任务

### GET /_nodes/hot_threads

183节点显示最频繁执行的是检索任务，没有获取其他有效信息

### GET /_nodes/stats/jvm

发现183节点young gc是另外两个节点的几十倍

### GET _cat/shards/{index}

检查主要索引的分片分布，发现两个问题:1、搜索引擎相关索引（knowledge_prod,Intention等）有两个主分片在183节点。搜索引擎相关索引是3主分片，每个主分片有1个副分片。2、其他应用索引都只有1个主分片

#### 处理

1. 通过reindex，重新分片搜索引擎相关索引分片分布

2. 其他应用后续考虑改为3主分片

手动分片再平衡后，问答引擎已经可以正常使用，但183资源占用仍然很高

### GET /_nodes/stats/indices/ 与 GET {index}/_stats

对比一段时间内，183节点索引访问数据与各主要索引的访问数据，发现问答引擎索引的search增长与183节点search增长差不多，怀疑问答引擎将请求全部打到183节点上

经过问答引擎排查，在search时，他们将preference设置为"1"，导致请求目标节点固定，而不是使用es的自适应副本选择。

[search-preference|Search API | Elasticsearch Guide [8.12] | Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html#search-preference)

# Redis

## 问题

海航现场Redis内存膨胀到23G+，与mongoDB形成资源竞争，影响正常业务使用

## 排查

通过脚本获取Redis内的bigkey与对应资源占用，发现"*AUTH_TOKEN*"有三千多，每条数据近1M；"*message_queue*"有近1万，最小为8k，最大为5M，肉眼预估平均应在2M左右，总量预估是20G左右。

临时处理方案将"*message_queue*"清除，释放后Redis占用近几百M

# MongoDB

## 问题

海航现场MongoDB内存占用20G+，且数次崩溃

## 排查

通过MongoDB日志发现部分高频查询没有走索引

## 处理

1. 为Mongo表添加合适的索引

2. 后续应该需要分表，高频访问大表不太合适

## 题外话

ES是很适合管理业务日志这里时序数据的，它有数据流、数据分层、生命周期管理、索引模板，可以自动管理数据分表，归档等。

假设数据量大时，可以考虑将提供检索与日志管理拆分为两个集群。因为检索服务适用同质集群扩展，而日志管理服务适用热温架构扩展

[在 Elastic Cloud 上的 Elasticsearch 服务中，如何针对日志和指标用例确定热温架构的规模](https://www.elastic.co/cn/blog/sizing-hot-warm-architectures-for-logging-and-metrics-in-the-elasticsearch-service-on-elastic-cloud)
