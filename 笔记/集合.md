# Map

## ConcurrentHashMap

### 初始化

在第一次put的时候初始化table数组，使用cas加锁；如果未设置当前容量，则会使用默认初始化16，如果设置了，则会初始化最近的2的n次方；如果以及有线程在执行初始化，则当前线程会调用yield()让出当前资源，然后忙轮询

### put流程

1. key与value都不允许为空

2. 校验是否已初始化数组，否则初始化；

3. 校验是否hash冲突，没有冲突则通过cas插入，hash冲突或者cas插入失败都进入下一步；

4. 校验是否正在扩容，如果是则当前线程帮助扩容；

5. 通过synchronized加锁处理hash冲突

### 扩容（tryPresize）与数据迁移（transfer）

1. 当hash冲突严重（需要转tree）且size小于64，则发起扩容；如果实际容量大于负载因子比例，则发起扩容

2. java将扩容操作根据cpu核数分为多个段，每段步长最少为16

3. 第一个发起数据迁移的线程会将 transferIndex 指向原数组最后的位置，然后从后往前的 stride 个任务属于第一个线程，然后将 transferIndex 指向新的位置，再往前的 stride 个任务属于第二个线程，依此类推。当然，这里说的第二个线程不是真的一定指代了第二个线程，也可以是同一个线程，这个读者应该能理解吧。其实就是将一个大的迁移任务分为了一个个任务包。

4. 数据迁移阶段，迁移成功会往原数组位置放入ForwardingNode，用来过度

5. 没有hash冲突的数据默认是以链表节点的方式存在hash桶中，迁移时按链表处理

6. transfer时会将链表拆分为两条，分别放高位与低位；通过位运算&计算

7. 红黑树也将被拆分为两棵树，如果tree节点小于6，则会转回链表

### 链表与红黑树的转换

1. 当桶内链表数超过8，且hash桶超过64；则开始将链表转换为红黑树

2. 当扩容后发现红黑树节点少于6时，红黑树转为链表

3. 当节点删除时，发现红黑树节点太小，会触发红黑树转链表，触发条件为：树根节点为空；左子树为空；右子树为空

#### 红黑树特质

红黑树是一棵二叉搜索树，它在每个节点增加了一个存储位记录节点的颜色，可以是RED,也可以是BLACK；通过任意一条从根到叶子简单路径上颜色的约束，红黑树保证最长路径不超过最短路径的二倍，因而近似平衡。

- 每个节点颜色不是黑色，就是红色
- 根节点是黑色的
- 如果一个节点是红色，那么它的两个子节点就是黑色的(没有连续的红节点)
- 对于每个节点，从该节点到其后代叶节点的简单路径上，均包含相同数目的黑色节点

### count计算

#### addCount流程

<img src="https://img-blog.csdnimg.cn/direct/d762ec5263ff48fc82e9ec38fd0e6914.jpeg" title="" alt="" width="476">

#### fullAddCount()

1. 数组不为空，优先对数组中CouterCell的value累加

2. CounterCell数组为空，并且没有线程在创建数组，修改标记，并创建数组

3. 数组为空，并且有别的线程在创建数组，那么尝试对baseCount做累加，

## HashMap

1. key与val都允许null

2. 在第一次put的时候初始化hash桶，默认为16，如果指定size，则是比size大，最近的2的n次方

3. 当桶内链表数超过8，且hash桶超过64；则开始将链表转换为红黑树；否则扩容

4. 每次扩容为原来的两倍，会将链表红黑树等结构拆分，如果红黑树拆分后容量小于6，则转回链表

5. 一般情况下删除红黑树下节点不会触发红黑树转链表，但当红黑树太小（根节点或左子树或右子树为空）时候会触发

## TreeMap

1. ***TreeMap*底层通过红黑树(Red-Black tree)实现**，也就意味着`containsKey()`, `get()`, `put()`, `remove()`都有着`log(n)`的时间复杂度

2. 因为底层是红黑树，所以treeMap是有序的，foreach或者Iterator使用中序遍历treeMap内的数据

3. 如果需要Map有序且要求并发，可以使用`ConcurrentSkipListMap`

## LinkedHashMap

1. 如果要使用java实现LRU算法，*LinkedHashMap* 是首选

2. LinkedHashMap继承HashMap，且自身维护了链表结构

3. put，remove等动作会直接调用hashmap方法，完成后再调用LinkedHashMap方法维护链表

4. LinkedHashMap遍历顺序为链表顺序

## ConcurrentSkipListMap

1. 底层由skipList(跳表)实现

2. 跳表的基本思想是将有序链表分层，每个节点在不同层中拥有不同数量的前向指针。上层链表是下层链表的子集，且上层链表中的元素顺序与下层链表一致。通过增加指针和添加层级的方式，跳表可以实现对数级别的查找效率。

3. 遍历跳表，找到比插入值大的第一个节点，插入

4. 获取随机数，根据抛硬币规则判断是否需要提升level，概率为四分之一

5. 根据随机数的二进制，判断有多少连续1，就提升多少层，上限是62

6. ConcurrentSkipListMap通过cas控制并发

7. SkipList 是空间换时间的数据结构，会比较耗内存

# List,QUEUE

## ArrayList

1. 底层是数组，对象初始化时初始化空数组，传入指定容量时，初始化为目标长度数组

2. 添加数据前，java会去校验list.size与底层数组的length是否相等，如果相等则扩容

3. 如果是首次添加数据，则会使用默认容量10，否则大约是1.5倍扩容

4. remove时需要将指定下标赋null，如果指定下标，则下标位置所有数据都需要前移，最后一位赋null

## LinkedList

底层是双向链表

## vector，synchronizedList与CopyOnWriteArrayList

| 类型                   | 缺点            | 优点                  |
| -------------------- | ------------- | ------------------- |
| vector               | 所有操作都要加锁，性能不佳 | 即使在高并发环境下都能保证数据的一致性 |
| synchronizedList     | 同上            | 同上                  |
| CopyOnWriteArrayList | 写操作会有一定的延迟    | 只有写加锁，读不加锁          |

### CopyOnWriteArrayList的缺陷和使用场景

CopyOnWriteArrayList 有几个缺点：

- 由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致young gc或者full gc

- 不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的,虽然CopyOnWriteArrayList 能做到最终一致性,但是还是没法满足实时性要求；

**CopyOnWriteArrayList 合适读多写少的场景，不过这类慎用**

因为谁也没法保证CopyOnWriteArrayList 到底要放置多少数据，万一数据稍微有点多，每次add/set都要重新复制数组，这个代价实在太高昂了。在高性能的互联网应用中，这种操作分分钟引起故障。

### CopyOnWriteArrayList为什么并发安全且性能比Vector好?

Vector对单独的add，remove等方法都是在方法上加了synchronized; 并且如果一个线程A调用size时，另一个线程B 执行了remove，然后size的值就不是最新的，然后线程A调用remove就会越界(这时就需要再加一个Synchronized)。这样就导致有了双重锁，效率大大降低，何必呢。于是vector废弃了，要用就用CopyOnWriteArrayList 吧。

## ArrayDeque

1. 底层由循环数组实现，由Object[] elements，int head，int tail组成

2. head或tail递增时，如果大于elements.length，则赋值为0

3. head或tail递减时，如果小于0，则赋值为elements.length-1

4. 当head == tail时代表数组满，需要扩容

5. addLast：tail+1；addFirst：head-1；

6. 当容量小于64时，双倍扩容，其他情况扩容到1.5倍

7. 扩容时，当tail<=head的时候，需要将head到数组末尾部分迁移到新数组的尾部

### 为什么 ArrayDeque 比 LinkedList 快

- ArrayDeque 基于数组实现双端队列，而 LinkedList 基于双向链表实现双端队列，数组采用连续的内存地址空间，通过下标索引访问，链表是非连续的内存地址空间，通过指针访问，所以在寻址方面数组的效率高于链表。

- 从内存的角度：虽然 LinkedList 没有扩容的问题，但是插入元素的时候，需要创建一个 Node 对象,换句话说每次都要执行 new 操作，当执行 new 操作的时候,其过程是非常慢的，会经历两个过程：类加载过程、对象创建过程。
